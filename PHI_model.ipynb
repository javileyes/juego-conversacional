{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7pqkPQTG9sw"
      },
      "source": [
        "https://youtu.be/QLZGg3YpsFM?si=ZpkTx9hboWU62FKt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7vM9MD3o0Jo"
      },
      "source": [
        "# Instalación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipsiG2Y-lhFs",
        "outputId": "82ea33fd-2ac9-4f42-9c4e-46fee845daeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jan 17 16:10:33 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.00                 Driver Version: 550.09       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4080        On  | 00000000:01:00.0 Off |                  N/A |\n",
            "|  0%   35C    P8              27W / 320W |      0MiB / 16376MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y8UPaY_ES3k",
        "outputId": "e361a0f8-7276-4799-fc32-c7c70bd8d02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m581.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-mi1cyr53\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-mi1cyr53\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit f4f57f9dfa68948a383c352a900d588f63f6290a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8340729 sha256=a00b549b5a326a5e5d17aaafd6ca09f7756774fd74675104a8767eab4ac4ec7f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i6zcttal/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.37.0.dev0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-2j6nwcs0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-2j6nwcs0\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=7561e93f959d1154cdcec0cb04e7aa171e67d3f0a36ed4b780806a235628aab6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0rl8a9pv/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers\n",
        "%pip install einops\n",
        "%pip install git+https://github.com/huggingface/transformers.git #accelerate\n",
        "%pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txqk6vzZR1xa"
      },
      "source": [
        "## Cargar el servidor en segundo plano con PM2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Servidor usando zephyr model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting server_zephyr.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile server_zephyr.py\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from threading import Lock\n",
        "import torch\n",
        "\n",
        "import time\n",
        "# Asegúrate de importar tu modelo Whisper correctamente\n",
        "# from tu_paquete import modelWhisper\n",
        "\n",
        "import whisper\n",
        "modelWhisper = whisper.load_model('medium')\n",
        "\n",
        "\n",
        "model_name = 'Helsinki-NLP/opus-mt-es-en'  # Modelo para traducir de español a inglés\n",
        "modelo_traductor = MarianMTModel.from_pretrained(model_name)\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def translate_text_to_english(text):\n",
        "    print(\"Traduciendo texto:\", text)\n",
        "    tokens = tokenizer(text, return_tensors='pt', padding=True)\n",
        "    translated = modelo_traductor.generate(**tokens)\n",
        "    decoded = []\n",
        "    for t in translated:\n",
        "        decoded.append(tokenizer.decode(t, skip_special_tokens=True))\n",
        "    \n",
        "    return decoded[0]\n",
        "\n",
        "\n",
        "modelo = \"zypher\"\n",
        "\n",
        "if modelo == \"mistral\":\n",
        "    from modelo_mistral_base import generate_long_chat, load_model\n",
        "elif modelo == \"zypher\":\n",
        "    from modelo_Zypher_beta import generate_long_chat, load_model\n",
        "else:\n",
        "    print(\"modelo no encontrado\")\n",
        "    exit()\n",
        "\n",
        "ai = \"assistant\"\n",
        "user = \"user\"\n",
        "\n",
        "contexto = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a kind and helpful assistan bot. You are here to help the user to find the best answer to his question.\n",
        "\"\"\"\n",
        "\n",
        "saludo = \"Hello, I am ready to receive and process your input.\"\n",
        "\n",
        "idioma = \"en\"\n",
        "\n",
        "import sys\n",
        "\n",
        "# Verifica si el comando tenía flag -s o --short\n",
        "if \"-s\" in sys.argv or \"--short\" in sys.argv:\n",
        "    short_answer = True\n",
        "\n",
        "# Si encuentra el flag -es cambia el idioma a español\n",
        "if \"-es\" in sys.argv:\n",
        "    idioma = \"es\"\n",
        "\n",
        "# Filtra los argumentos para eliminar los flags\n",
        "args = [arg for arg in sys.argv[1:] if arg not in [\"-s\", \"--short\", \"-es\"]]\n",
        "\n",
        "# Asigna los valores a system_prompt y saludo basándose en los argumentos restantes\n",
        "if len(args) > 0:\n",
        "    system_prompt = args[0]\n",
        "if len(args) > 1:\n",
        "    saludo = args[1]\n",
        "\n",
        "if modelo == \"mistral\":\n",
        "    historico = f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n<|im_start|>assistant\\n{saludo}<|im_end|>\\n\"\n",
        "elif modelo == \"zypher\":    \n",
        "    historico = f\"<|system|>{system_prompt}</s>\\n<|assistant|>\\n{saludo}</s>\\n\"\n",
        "\n",
        "\n",
        "# load model\n",
        "load_model(user=user, ai=ai)\n",
        "\n",
        "print(f\"{ai}:\", saludo)\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de transcribir\n",
        "transcribe_lock = Lock()\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de traducir\n",
        "translate_lock = Lock()\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de generar texto\n",
        "generate_lock = Lock()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/transcribe', methods=['POST'])\n",
        "def transcribe_audio():\n",
        "    global historico\n",
        "    global user\n",
        "    global ai\n",
        "    # global iteracion\n",
        "\n",
        "    # Comprueba si el archivo fue enviado\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify(error=\"No file part\"), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    # Comprueba si el usuario no seleccionó un archivo\n",
        "    if file.filename == '':\n",
        "        return jsonify(error=\"No selected file\"), 400\n",
        "\n",
        "    # Genera un nombre de archivo único utilizando una marca de tiempo\n",
        "    timestamp = int(time.time() * 1000)  # Marca de tiempo en milisegundos\n",
        "    mp3_filepath = f\"received_audio_{timestamp}.mp3\"\n",
        "    file.save(mp3_filepath)\n",
        "\n",
        "    # Transcribe el archivo MP3 (Asegúrate de tener el modelo cargado correctamente)\n",
        "    # Transcribe el archivo MP3 dentro de una sección crítica protegida por un bloqueo\n",
        "    with transcribe_lock:\n",
        "        # transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False)\n",
        "        # transcipción lenguaje inglés\n",
        "        transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=idioma)\n",
        "        transcripcion = transcripcion[\"text\"]\n",
        "        print(\"transcripción:\", transcripcion)\n",
        "\n",
        "    # si el idioma es español, traduce la transcripción al inglés\n",
        "    if idioma == \"es\":\n",
        "        with translate_lock:\n",
        "            transcripcion = translate_text_to_english(transcripcion)\n",
        "            print(\"traducción:\", transcripcion)\n",
        "\n",
        "    prompt = f\"{historico}\\n{user}:{transcripcion}\\n{ai}:\"\n",
        "    print(\"prompt:\", prompt)\n",
        "\n",
        "\n",
        "    with generate_lock:\n",
        "        historico, output = generate_long_chat(historico, ai, user, input_text=transcripcion, max_additional_tokens=2048, short_answer=short_answer, streaming=False, printing=False)\n",
        "        print(\"output:\", output)\n",
        "        # print(\"historico:\", historico)\n",
        "\n",
        "\n",
        "    return jsonify(transcripcion=output)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5500, threaded=True)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting zephyr_model_talker.config.js\n"
          ]
        }
      ],
      "source": [
        "%%writefile zephyr_model_talker.config.js\n",
        "module.exports = {\n",
        "  apps: [\n",
        "    {\n",
        "      name: \"zephyr_model_talker\",\n",
        "      script: \"server_zephyr.py\",\n",
        "      args: [\"--short\", \"-es\", \"You are the CEO of a consulting company called mAgIc, dedicated to finding artificial intelligence solutions for companies. You are interviewing a candidate to work for the company, you are interested in programming skills, mathematics, data science, AI and especially NLP. Ask questions about all this and probe. If the candidate says something wrong let them know.\", \"Good morning, have a seat, tell me your name.\"],\n",
        "      out_file: \"out.log\",\n",
        "      error_file: \"err.log\",\n",
        "      log_file: \"combined.log\",\n",
        "      time: true,\n",
        "    },\n",
        "  ],\n",
        "};\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m[PM2][WARN] \u001b[39mApplications zephyr_model_talker not running, starting...\n",
            "\u001b[32m[PM2] \u001b[39mApp [zephyr_model_talker] launched (1 instances)\n",
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────┼──────────┼──────┼───────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m zephyr_model_talk… \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 5.3mb    \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 start zephyr_model_talker.config.js"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────┼──────────┼──────┼───────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m zephyr_model_talk… \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 13.2gb   \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[PM2] \u001b[39mApplying action stopProcessId on app [0](ids: [ '0' ])\n",
            "\u001b[32m[PM2] \u001b[39m[zephyr_model_talker](0) ✓\n",
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────┼──────────┼──────┼───────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m zephyr_model_talk… \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m     \u001b[90m│\u001b[39m 12   \u001b[90m│\u001b[39m \u001b[31m\u001b[1mstopped\u001b[22m\u001b[39m   \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 0b       \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n",
            "\u001b[32m[PM2] \u001b[39mApplying action deleteProcessId on app [0](ids: [ '0' ])\n",
            "\u001b[32m[PM2] \u001b[39m[zephyr_model_talker](0) ✓\n",
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 stop 0\n",
        "!pm2 delete 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Servidor usando phi-1.5 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYjIzSHdqX0a",
        "outputId": "db7e54c5-7c42-4cbc-c02d-cbbb890ded2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing server_phi_1_5.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile server_phi_1_5.py\n",
        "from flask import Flask, request, jsonify\n",
        "from threading import Lock\n",
        "import torch\n",
        "\n",
        "import time\n",
        "# Asegúrate de importar tu modelo Whisper correctamente\n",
        "# from tu_paquete import modelWhisper\n",
        "\n",
        "import whisper\n",
        "modelWhisper = whisper.load_model('medium')\n",
        "\n",
        "\n",
        "# carga modelo PHI-1.5\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "torch.set_default_device('cuda')\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "\n",
        "max_additional_tokens = 50  # Establece tu límite para el número de tokens adicionales aquí\n",
        "\n",
        "def find_nth_occurrence(string, substring, n):\n",
        "    start = 0\n",
        "    for _ in range(n):\n",
        "        start = string.find(substring, start) + 1\n",
        "        if start == 0:\n",
        "            return -1\n",
        "    return start - 1\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de transcribir\n",
        "transcribe_lock = Lock()\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de generar texto\n",
        "generate_lock = Lock()\n",
        "\n",
        "# ai = \"Alice:\"\n",
        "# user = \"Bob:\"\n",
        "\n",
        "# historico = f\"Contexto, {ai} is a high school teacher, she like play tennis and watch television. This is the firs time {ai} and {user} meet.\\n\"\n",
        "\n",
        "iteracion = 0\n",
        "\n",
        "ai = \"King Arthur\"\n",
        "user = \"Bob\"\n",
        "\n",
        "historico = f\"Context: {user}, a commoner, talk alone with {ai}.\\n\"\n",
        "\n",
        "@app.route('/transcribe', methods=['POST'])\n",
        "def transcribe_audio():\n",
        "    global historico\n",
        "    global user\n",
        "    global ai\n",
        "    global iteracion\n",
        "\n",
        "    # Comprueba si el archivo fue enviado\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify(error=\"No file part\"), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    # Comprueba si el usuario no seleccionó un archivo\n",
        "    if file.filename == '':\n",
        "        return jsonify(error=\"No selected file\"), 400\n",
        "\n",
        "    # Genera un nombre de archivo único utilizando una marca de tiempo\n",
        "    timestamp = int(time.time() * 1000)  # Marca de tiempo en milisegundos\n",
        "    mp3_filepath = f\"received_audio_{timestamp}.mp3\"\n",
        "    file.save(mp3_filepath)\n",
        "\n",
        "    # Transcribe el archivo MP3 (Asegúrate de tener el modelo cargado correctamente)\n",
        "    # Transcribe el archivo MP3 dentro de una sección crítica protegida por un bloqueo\n",
        "    with transcribe_lock:\n",
        "        # transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False)\n",
        "        # transcipción lenguaje inglés\n",
        "        transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=\"en\")\n",
        "        transcripcion = transcripcion[\"text\"]\n",
        "\n",
        "    prompt = f\"{historico}\\n{user}:{transcripcion}\\n{ai}:\"\n",
        "    print(\"prompt:\", prompt)\n",
        "\n",
        "\n",
        "    # Asegúrate de que tanto el modelo como los inputs están en el dispositivo GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    with generate_lock:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "\n",
        "        input_length = inputs[\"input_ids\"].size(1)  # Obtén el número de tokens en la entrada\n",
        "\n",
        "        max_additional_tokens = 50  # Establece tu límite para el número de tokens adicionales aquí\n",
        "        # Generar texto normalmente sin usar early_stopping para la cadena\n",
        "        outputs = model.generate(**inputs, max_length=input_length + max_additional_tokens)\n",
        "\n",
        "        # Decodificar el texto generado\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        print(\"output_generated_text:\", generated_text)\n",
        "\n",
        "        # Encuentra la n-ésima ocurrencia del nombre que tenga ai\n",
        "        n = iteracion + 2  # Cambia este valor para encontrar una ocurrencia diferente\n",
        "        print(\"n:\", n)\n",
        "        start_index = find_nth_occurrence(generated_text, f\"{ai}:\", n-1) + len(f\"{ai}:\")\n",
        "        stop_index = find_nth_occurrence(generated_text, f\"{user}:\", n)\n",
        "        # si no genera respuesta ficticia de usuario cortamos en el primer salto de linea\n",
        "        if stop_index == -1:\n",
        "            stop_index =  generated_text.find(\"\\n\", start_index) - 1\n",
        "\n",
        "        # Si encontramos la n-ésima ocurrencia, cortamos el texto en ese punto\n",
        "        if stop_index != -1:\n",
        "            historico = generated_text[:stop_index]\n",
        "            generated_text = generated_text[start_index:stop_index]\n",
        "\n",
        "        print(\"generated_text:\", generated_text)\n",
        "        iteracion += 1\n",
        "    # # Devuelve la transcripción\n",
        "    return jsonify(transcripcion=generated_text)\n",
        "    # Devuelve la transcripción\n",
        "    # return jsonify(transcripcion={\"text\": transcripcion})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5500, threaded=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OwPqgoMNyU1",
        "outputId": "846ad6a9-b7a2-4467-9888-d0e50adfbb4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ecosystem.config.js\n"
          ]
        }
      ],
      "source": [
        "%%writefile ecosystem.config.js\n",
        "module.exports = {\n",
        "  apps: [\n",
        "    {\n",
        "      name: \"phi_model_talker\",\n",
        "      script: \"server_phi_1_5.py\",\n",
        "      out_file: \"out.log\",\n",
        "      error_file: \"err.log\",\n",
        "      log_file: \"combined.log\",\n",
        "      time: true,\n",
        "    },\n",
        "  ],\n",
        "};\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J0VcVuECLxnT"
      },
      "outputs": [],
      "source": [
        "# Comando pm2 sirve para demonizar de forma muy robusta aplicaciones o comandos (es muy necesario para no bloquear entorno colab -cuaderno jupyter)\n",
        "# https://pm2.keymetrics.io/docs/usage/quick-start/\n",
        "# otra forma de instalarlo:\n",
        "#!curl -sL https://raw.githubusercontent.com/Unitech/pm2/master/packager/setup.deb.sh | sudo -E bash -\n",
        "!npm install pm2 -g > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HavtJ8hBLt9T",
        "outputId": "a7a81a5e-13eb-4dac-d078-164d45669450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m[PM2][WARN] \u001b[39mApplications phi_model_talker not running, starting...\n",
            "\u001b[32m[PM2] \u001b[39mApp [phi_model_talker] launched (1 instances)\n",
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────┼──────────┼──────┼───────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m phi_model_talker   \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 5.8mb    \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 start ecosystem.config.js"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcWndJjPSxa7",
        "outputId": "447c2382-a8ac-4530-c7e6-46ec7477765c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VDVM5dc6QFgu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[PM2] \u001b[39mApplying action stopProcessId on app [0](ids: [ '0' ])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[PM2] \u001b[39m[phi_model_talker](0) ✓\n",
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────┼──────────┼──────┼───────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m phi_model_talker   \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[31m\u001b[1mstopped\u001b[22m\u001b[39m   \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 0b       \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n",
            "\u001b[32m[PM2] \u001b[39mApplying action deleteProcessId on app [0](ids: [ '0' ])\n",
            "\u001b[32m[PM2] \u001b[39m[phi_model_talker](0) ✓\n",
            "\u001b[90m┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m memory   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 stop 0\n",
        "!pm2 delete 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora podemos ver el log que hay en los ficheros de log de PM2:\n",
        "\n",
        "Podemos comprobar que el puerto funciona correctamente con comando netcat, por ejemplo en el caso de saber la IP y el puerto del servidor (si hubiera un firewall habría que abrir el puerto en el firewall):\n",
        "\n",
        "```bash\n",
        "nc -vz 192.168.1.142 5500\n",
        "```\n",
        "\n",
        "Si se quiere ejecutar en la misma red o el servidor tiene una ip pública, no haría falta crear tunel, solo habría que ejecutar el cliente con la ip del servidor y el puerto que se haya configurado en el servidor y el servicio de transcripción.\n",
        "Por ejemplo:\n",
        "NOTA: Es importante poner http:// delante de la ip del servidor para que no de error.\n",
        "\n",
        "```bash:\n",
        "\n",
        "python whisperWalkieTalkie.py http://192.168.1.142:5500/transcribe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP-ukPy3TA9J"
      },
      "source": [
        "## Crear tunel para abrir el servicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSwc22rwD4uo"
      },
      "source": [
        "### Preparamos entorno para poder crear tunel ssh con javiergimenez.es:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LbaEuOMAHRf"
      },
      "source": [
        "Como lo que queremos es poder crear tuneles inversos desde el virtual server del Google Colab hasta un VPS con IP pública. Debemos crear un par de claves pública-privada, dejando la private-key en el fichero /root/.ssh/id_rsa del Colab y la public.key en el /home/tuusuario/.ssh/authorized_keys de tu VPS\n",
        "\n",
        "```\n",
        "ssh-keygen -t rsa\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eWAfh8eb54QH"
      },
      "outputs": [],
      "source": [
        "!mkdir /root/.ssh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f3zxvhFf4bSk"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat << EOF > /root/.ssh/id_rsa\n",
        "-----BEGIN RSA PRIVATE KEY-----\n",
        "MIIEpgIBAAKCAQEAuLjteVnjiF2GRhuJ35wRl3O5jzl5Y/3eh7b/mBfXntpuDX/c\n",
        "ANSjL9VLNEmvnSvy5Y/+Vx6N7OrDWao07ZIksf/a1u+HOZP7e387W4EDYyifcP4V\n",
        "orrhtwi6OxdPLQg20GDD/RqGtiTCx66iJLxyWLmG4n33fPrItg5/FQHLVo3gtaDI\n",
        "ga4lq5+v+Id/01s71gk+5mZdEMWLV7WpWpEKvJ5kmP1qZeD7PCjP6eRUKYdAh3i2\n",
        "rDxSHmL4KKp4KNca+krichDL18Pqw3IfzlgYkpyyiixxHqBjXSVBo6lquXtwdSS5\n",
        "ujy+iW29JR7PABt7HUAMUrN/6bmaPf7ip7c/LQIDAQABAoIBAQCYRCfMbiI2mBFE\n",
        "3RJrdnSxyTzeKNw9Zlj2ugw6TPz5/sfU7N5m+OCDX2icc1kFT+LrBCT9nzwSXPom\n",
        "gT0bz+nbqDG2Fr/64FbeV+SP6url4+h59ZfUCgRhIhqQ9wfW8PxuDDXB/wmoPuko\n",
        "PHV/nq8LH/Nl47wME5U7LPvoTxBUCTvgmRblPPVjLZ25joUcnZ2wT0vXMTvkJ/Hk\n",
        "JJ3qKeZFjr/rFNwJS1P5WZE6qWHthK3722Oxdkxwk1Bz1XYymzsJNugC2A/q6Pro\n",
        "/35bLuwjrgHCEY6SEOpqYHMd3a9VMcs0Y4VERcn4Vp4KceKcmTK5mOKFtjSb8RpK\n",
        "T0809v0BAoGBAOtHL0/FreJZZkP+u9GpkXSUq7aDjL4WyKd31xDmNH1p1QKGIj2K\n",
        "pK8qw5Zfj0ndx1v3AKtBTrt/qs8IyKEP17Dc5DEMKq3DCXT72ZOqoXJvUEmbMNHC\n",
        "wyRAc2SWrUx1oaHGBiqQrOQZq7bVE/IMWhVwNCi/Nrz6bGRnXgM1dP0NAoGBAMj9\n",
        "3Q3yz5BiEO3Z/NGQ9Ud4C+uWCJsczzUxKoeqfTW5bKgTfzfSPomON8Rxep2+k9pJ\n",
        "vYvOldXl3nlKUFvNjv4f7pPIGwvhG+Z81aI89K7m3lR6/8BwAbH3GjlVM1RDrMSP\n",
        "pAjAcM2t18/ZZuUvmRn+TzU7gzuwPSd0QxgVUgKhAoGBAOM6se/qbIDCdOlQmZbp\n",
        "nSip+ZlhPcnM+Wf8bwLMQn+peedhIqqrP1hKBfIyQpJFlqg0Szoa7e5aY95mjlY3\n",
        "lcoj3GOea428Y2LPZhie4CREa5dbQfAkmRFnCctpVuAUb9FtDkGHzuLSBCylaAkK\n",
        "cupnnoiH/FbRyWPDDWIt+9n1AoGBAKoMFjUR5Ehcn8QMdNh9EvfnefZUlm1dX3W6\n",
        "Zigntw14FpTRAgYhS6WnfEkoVTwWnBLH5qTdIGm6tJHbrMcuz7bzHy9K0o8nYiqM\n",
        "HVbIyZ8cVqgU9EJEwTpnPHmbOvUk2IvolziMUCPD293PKj3nGloijbMU6b/bKLIz\n",
        "q/w5NYxhAoGBALUTaTwTyNhqBG0mNVRQX56IYkPPDcD3tVyI5+Y6gdr8g4QLOnAI\n",
        "DF5zbgJxISyJIAQm5KPbs401eiBpoDPNk20yJcJryMiFPsFNBLndASqyKTF0xujr\n",
        "tPLMj6ZI/CesbNAVK/2xAn+twz4EEOABgKudPGsUHHaonIISLhqGaXG7\n",
        "-----END RSA PRIVATE KEY-----\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMdfzDKV6AFx"
      },
      "source": [
        "Esta línea de abajo es para evitar este error:\n",
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @\n",
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "Permissions 0644 for '/root/.ssh/vm/vm_id_rsa.pub' are too open.\n",
        "It is required that your private key files are NOT accessible by others.\n",
        "This private key will be ignored.\n",
        "bad permissions: ignore key: /root/.ssh/vm/vm_id_rsa.pub\n",
        "Permission denied (publickey,password)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RNmMNlSR6N-4"
      },
      "outputs": [],
      "source": [
        "!chmod 400 /root/.ssh/id_rsa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJrAO41nXpIp"
      },
      "source": [
        "\n",
        "Esto se pondría en cualquier servidor ssh para acceder por clave pública\n",
        "```\n",
        "cat << EOF > /home/un_usuario/.ssh/authorized_keys\n",
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC4uO15WeOIXYZGG4nfnBGXc7mPOXlj/d6Htv+YF9ee2m4Nf9wA1KMv1Us0Sa+dK/Llj/5XHo3s6sNZqjTtkiSx/9rW74c5k/t7fztbgQNjKJ9w/hWiuuG3CLo7F08tCDbQYMP9Goa2JMLHrqIkvHJYuYbiffd8+si2Dn8VActWjeC1oMiBriWrn6/4h3/TWzvWCT7mZl0QxYtXtalakQq8nmSY/Wpl4Ps8KM/p5FQph0CHeLasPFIeYvgoqngo1xr6SuJyEMvXw+rDch/OWBiSnLKKLHEeoGNdJUGjqWq5e3B1JLm6PL6Jbb0lHs8AG3sdQAxSs3/puZo9/uKntz8t root@cb68bbd911b6\n",
        "EOF\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igorzQdn5kqQ"
      },
      "source": [
        "Esta línea de shell es para evitar este error:\n",
        "\n",
        "\"Host Key Verification Failed\" when connecting to remote repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKvlf55w0tIB",
        "outputId": "1d56c1b7-5071-470e-c639-087efde06866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# javiergimenez.es:22 SSH-2.0-OpenSSH_7.4\n"
          ]
        }
      ],
      "source": [
        "!ssh-keyscan -t rsa javiergimenez.es >> ~/.ssh/known_hosts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFPT0S-vY5Hb"
      },
      "source": [
        "<H2> Ya podemos conectarnos via ssh a nuestro servidor: </H2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_PSYMnnJWv7",
        "outputId": "14fa517e-05c5-459c-e6be-8ca575141fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active Internet connections (only servers)\n",
            "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \n",
            "tcp        0      0 127.0.0.1:42918         0.0.0.0:*               LISTEN      17009/node          \n",
            "tcp        0      0 127.0.0.1:9000          0.0.0.0:*               LISTEN      17369/python3       \n",
            "tcp        0      0 127.0.0.1:9001          0.0.0.0:*               LISTEN      17369/python3       \n",
            "tcp        0      0 127.0.0.1:9002          0.0.0.0:*               LISTEN      17369/python3       \n",
            "tcp        0      0 127.0.0.1:9003          0.0.0.0:*               LISTEN      17369/python3       \n",
            "tcp        0      0 127.0.0.1:9004          0.0.0.0:*               LISTEN      17369/python3       \n",
            "tcp        0      0 127.0.0.1:35694         0.0.0.0:*               LISTEN      17205/code-af28b32d \n",
            "tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      28984/python3.6     \n",
            "tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN      6961/python3.6      \n",
            "tcp        0      0 0.0.0.0:10000           0.0.0.0:*               LISTEN      738/perl            \n",
            "tcp        0      0 127.0.0.1:38996         0.0.0.0:*               LISTEN      17132/node          \n",
            "tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1041/sshd           \n",
            "tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      1202/master         \n",
            "tcp        0      0 127.0.0.1:43964         0.0.0.0:*               LISTEN      17369/python3       \n",
            "tcp6       0      0 :::22                   :::*                    LISTEN      1041/sshd           \n",
            "tcp6       0      0 ::1:25                  :::*                    LISTEN      1202/master         \n"
          ]
        }
      ],
      "source": [
        "!ssh root@javiergimenez.es \"netstat -tlnp\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rUIwRzWL8_Es"
      },
      "outputs": [],
      "source": [
        "# !apt install net-tools > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c7WHNJiXoV2O"
      },
      "outputs": [],
      "source": [
        "# !netstat -tlnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0amtSwoIR9Gm",
        "outputId": "e5d80a85-bb5a-4cfd-fa25-06bcf925cc15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                                  \n",
            "LISTEN 0      4096       127.0.0.1:36069      0.0.0.0:*    users:((\"python3\",pid=749,fd=4))        \n",
            "LISTEN 0      128        127.0.0.1:3453       0.0.0.0:*    users:((\"colab-fileshim.\",pid=60,fd=3)) \n",
            "LISTEN 0      4096     172.28.0.12:6000       0.0.0.0:*    users:((\"kernel_manager_\",pid=21,fd=7)) \n",
            "LISTEN 0      100        127.0.0.1:43491      0.0.0.0:*    users:((\"python3\",pid=710,fd=21))       \n",
            "LISTEN 0      4096       127.0.0.1:46749      0.0.0.0:*    users:((\"python3\",pid=749,fd=3))        \n",
            "LISTEN 0      128      172.28.0.12:9000       0.0.0.0:*    users:((\"jupyter-noteboo\",pid=110,fd=7))\n",
            "LISTEN 0      4096      127.0.0.11:44395      0.0.0.0:*                                            \n",
            "LISTEN 0      511                *:8080             *:*    users:((\"node\",pid=7,fd=21))            \n"
          ]
        }
      ],
      "source": [
        "!ss -ltnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh8m4Iz2e_CY",
        "outputId": "b56423f3-4d4a-472b-af33-9c1858887e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing /root/buscaPuerto.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile /root/buscaPuerto.sh\n",
        "set puerto=$(expr 50000 + $RANDOM % 15000)\n",
        "netstat -tnl | grep \":${puerto}\" >/dev/null\n",
        "while [ \"$?\" -eq 0 ]; do\n",
        "     puerto=$(expr 50000 + $RANDOM % 15000)\n",
        "     netstat -tnl | grep \":${puerto}\" >/dev/null\n",
        "done\n",
        "#echo \"Puerto libre para conexión del tunel:\"\n",
        "echo \"${puerto}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6hgAhGXfTCTQ"
      },
      "outputs": [],
      "source": [
        "#EJECUTAR SI NO EXISTIERA EL SCRIPT EN EL SERVIDOR:\n",
        "#!scp /root/buscaPuerto.sh asir@javiergimenez.es:/home/asir/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5va6Seus1Q1"
      },
      "source": [
        "### crear tunel ssh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YqRZasjfs3XH",
        "outputId": "bb30e5b5-5589-4bc4-8d69-59f8fdc02f85"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'51399'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "puertoLLM = !ssh asir@javiergimenez.es \"sh buscaPuerto.sh\"\n",
        "puertoLLM = puertoLLM[0]\n",
        "puertoLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgrBzcxbtIq6",
        "outputId": "ec8e432f-d0d1-4bec-faa5-f39e87545966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[PM2] \u001b[39mStarting /usr/bin/bash in fork_mode (1 instance)\n",
            "\u001b[32m[PM2] \u001b[39mDone.\n",
            "\u001b[90m┌────┬────────────────────────────────────────────────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name                                               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m namespace   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m version \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m pid      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m uptime \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mem      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m user     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m watching \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────────────────────────────────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m phi_model_talker                                   \u001b[90m│\u001b[39m default     \u001b[90m│\u001b[39m N/A     \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m    \u001b[90m│\u001b[39m 1291     \u001b[90m│\u001b[39m 6s     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 391.6mb  \u001b[90m│\u001b[39m \u001b[1mroot\u001b[22m     \u001b[90m│\u001b[39m \u001b[90mdisabled\u001b[39m \u001b[90m│\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m1\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m ssh  -R 51399:localhost:5500 root@javiergimenez    \u001b[90m│\u001b[39m default     \u001b[90m│\u001b[39m N/A     \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m    \u001b[90m│\u001b[39m 1352     \u001b[90m│\u001b[39m 0s     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 8.0kb    \u001b[90m│\u001b[39m \u001b[1mroot\u001b[22m     \u001b[90m│\u001b[39m \u001b[90mdisabled\u001b[39m \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────────────────────────────────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘\u001b[39m\n",
            "servidor: javiergimenez.es\n",
            "puerto: 51399\n"
          ]
        }
      ],
      "source": [
        "#creo tunel ssh en segundo plano hacia mi servidor para acceder al servicio web de la aplicación web gestora de Neo4J.\n",
        "!pm2 start \"ssh  -R {puertoLLM}:localhost:5500 root@javiergimenez.es\"\n",
        "!echo \"servidor: javiergimenez.es\"\n",
        "!echo \"puerto: {puertoLLM}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw-uIAV1tbgo",
        "outputId": "e26cb9c1-eba5-47d4-c661-ebdd6cfbbd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                                  \n",
            "LISTEN 0      4096       127.0.0.1:36069      0.0.0.0:*    users:((\"python3\",pid=749,fd=4))        \n",
            "LISTEN 0      128        127.0.0.1:3453       0.0.0.0:*    users:((\"colab-fileshim.\",pid=60,fd=3)) \n",
            "LISTEN 0      4096     172.28.0.12:6000       0.0.0.0:*    users:((\"kernel_manager_\",pid=21,fd=7)) \n",
            "LISTEN 0      100        127.0.0.1:43491      0.0.0.0:*    users:((\"python3\",pid=710,fd=21))       \n",
            "LISTEN 0      4096       127.0.0.1:46749      0.0.0.0:*    users:((\"python3\",pid=749,fd=3))        \n",
            "LISTEN 0      128      172.28.0.12:9000       0.0.0.0:*    users:((\"jupyter-noteboo\",pid=110,fd=7))\n",
            "LISTEN 0      4096      127.0.0.11:44395      0.0.0.0:*                                            \n",
            "LISTEN 0      511                *:8080             *:*    users:((\"node\",pid=7,fd=21))            \n"
          ]
        }
      ],
      "source": [
        "!ss -ltnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilUiztpYt0IA",
        "outputId": "b219940f-57a2-4243-e2b3-c1bb5b6d8a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m┌────┬────────────────────────────────────────────────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m id \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m name                                               \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m namespace   \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m version \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mode    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m pid      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m uptime \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m ↺    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m status    \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m cpu      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m mem      \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m user     \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\u001b[1m\u001b[36m watching \u001b[39m\u001b[22m\u001b[90m│\u001b[39m\n",
            "\u001b[90m├────┼────────────────────────────────────────────────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m0\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m phi_model_talker                                   \u001b[90m│\u001b[39m default     \u001b[90m│\u001b[39m N/A     \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m    \u001b[90m│\u001b[39m 1291     \u001b[90m│\u001b[39m 7s     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 419.0mb  \u001b[90m│\u001b[39m \u001b[1mroot\u001b[22m     \u001b[90m│\u001b[39m \u001b[90mdisabled\u001b[39m \u001b[90m│\u001b[39m\n",
            "\u001b[90m│\u001b[39m\u001b[1m\u001b[36m \u001b[1m\u001b[36m1\u001b[39m\u001b[36m\u001b[22m\u001b[1m  \u001b[39m\u001b[22m\u001b[90m│\u001b[39m ssh  -R 51399:localhost:5500 root@javiergimenez    \u001b[90m│\u001b[39m default     \u001b[90m│\u001b[39m N/A     \u001b[90m│\u001b[39m \u001b[7m\u001b[1mfork\u001b[22m\u001b[27m    \u001b[90m│\u001b[39m 1352     \u001b[90m│\u001b[39m 0s     \u001b[90m│\u001b[39m 0    \u001b[90m│\u001b[39m \u001b[32m\u001b[1monline\u001b[22m\u001b[39m    \u001b[90m│\u001b[39m 0%       \u001b[90m│\u001b[39m 7.5mb    \u001b[90m│\u001b[39m \u001b[1mroot\u001b[22m     \u001b[90m│\u001b[39m \u001b[90mdisabled\u001b[39m \u001b[90m│\u001b[39m\n",
            "\u001b[90m└────┴────────────────────────────────────────────────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!pm2 list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVtC8H8zuBiI",
        "outputId": "57159350-1274-4d0c-f0a8-42e2fafd8171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://javiergimenez.es:51399/transcribe\n"
          ]
        }
      ],
      "source": [
        "!echo \"http://javiergimenez.es:{puertoLLM}/transcribe\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-1Iv9FzYYVm"
      },
      "source": [
        "# Descargar el instalador de cliente para Linux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKv08RYGYeKC",
        "outputId": "b6a678b5-cc13-477b-fdaa-6153be8b1852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing instalador.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile instalador.sh\n",
        "#!/bin/bash\n",
        "\n",
        "# Comprueba si Conda está instalado\n",
        "if ! command -v conda &> /dev/null; then\n",
        "    echo \"Conda no se encuentra instalado, instalando Miniconda...\"\n",
        "\n",
        "    # Descarga y ejecuta el script de instalación de Miniconda\n",
        "    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "    bash miniconda.sh -b -p $HOME/miniconda\n",
        "\n",
        "    # Inicializa Conda\n",
        "    source $HOME/miniconda/etc/profile.d/conda.sh\n",
        "    CONDA_BASE=$HOME/miniconda\n",
        "else\n",
        "    echo \"Conda está instalado.\"\n",
        "    CONDA_BASE=$(conda info --base)\n",
        "fi\n",
        "\n",
        "# Crea un nuevo entorno Conda\n",
        "conda create -n IA python=3.8 -y\n",
        "\n",
        "# Asegúrate de que pip esté instalado en el entorno conda\n",
        "conda install -n IA pip -y\n",
        "\n",
        "# Usa pip para instalar los paquetes en el entorno conda\n",
        "$CONDA_BASE/envs/IA/bin/pip install ffmpeg SpeechRecognition pyaudio pydub gtts pynput simpleaudio requests\n",
        "\n",
        "# Activa el nuevo entorno\n",
        "#conda activate IA\n",
        "\n",
        "\n",
        "# Crea el archivo cliente.py a partir de un archivo HERE\n",
        "cat <<EOL > cliente.py\n",
        "\n",
        "import sys\n",
        "\n",
        "if len(sys.argv) > 1:\n",
        "    servidor = sys.argv[1]\n",
        "    print(f\"El primer argumento pasado es: {servidor}\")\n",
        "else:\n",
        "    print(\"No se pasó ningún argumento de conexión a ningún servidor.\")\n",
        "\n",
        "import requests\n",
        "import threading\n",
        "\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "from gtts import gTTS\n",
        "\n",
        "from pynput import keyboard\n",
        "import simpleaudio as sa\n",
        "import sys\n",
        "\n",
        "\n",
        "def on_press(key):\n",
        "    global start_recording\n",
        "    if key == keyboard.Key.space:\n",
        "        start_recording.set()\n",
        "\n",
        "def on_release(key):\n",
        "    global start_recording, stop_recording, exit_flag\n",
        "    if key == keyboard.Key.space:\n",
        "        start_recording.clear()\n",
        "        stop_recording.set()\n",
        "    elif key == keyboard.Key.esc:\n",
        "        exit_flag.set()\n",
        "        # Stop listener\n",
        "        return False\n",
        "\n",
        "# Define las variables de control\n",
        "start_recording = threading.Event()\n",
        "stop_recording = threading.Event()\n",
        "exit_flag = threading.Event()\n",
        "\n",
        "# Inicia el listener de teclado\n",
        "keyboard_listener = keyboard.Listener(on_press=on_press, on_release=on_release)\n",
        "keyboard_listener.start()\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "iteration = 0\n",
        "\n",
        "\n",
        "def text_to_speech(text, file_name, language):\n",
        "    tts = gTTS(text=text, lang=language)\n",
        "    tts.save(file_name)\n",
        "\n",
        "def play_audio(file_name):\n",
        "    # Cargamos el archivo de audio\n",
        "    audio_segment = AudioSegment.from_mp3(file_name)\n",
        "\n",
        "    # Convertimos el archivo MP3 a un archivo WAVE\n",
        "    wave_file_name = file_name.replace(\".mp3\", \".wav\")\n",
        "    audio_segment.export(wave_file_name, format=\"wav\")\n",
        "\n",
        "    # Convertimos el audio_segment a un objeto wave\n",
        "    wave_obj = sa.WaveObject.from_wave_file(wave_file_name)\n",
        "\n",
        "    # Reproducimos el audio\n",
        "    play_obj = wave_obj.play()\n",
        "    play_obj.wait_done()  # Espera hasta que el audio termine de reproducirse\n",
        "\n",
        "\n",
        "\n",
        "def send_audio_to_server(mp3_file, wav_file):\n",
        "    # Convierte el archivo WAV a MP3\n",
        "    AudioSegment.from_wav(wav_file).export(mp3_file, format=\"mp3\")\n",
        "\n",
        "\n",
        "    # Envía el archivo MP3 a un servidor\n",
        "    # url = \"http://ia.javiergimenez.es:5500/transcribe\"\n",
        "    # url = \"http://192.168.1.142:5500/transcribe\"\n",
        "    url = servidor\n",
        "\n",
        "    with open(mp3_file, 'rb') as f:\n",
        "        response = requests.post(url, files={'file': f})\n",
        "\n",
        "    # Muestra la respuesta del servidor\n",
        "    response_data = response.json()  # Deserializa la respuesta JSON a un diccionario\n",
        "    transcripcion = response_data.get(\"transcripcion\", {})#.get(\"text\", \"No se pudo obtener la transcripción\")\n",
        "    print(\"Respuesta del servidor:\", transcripcion)\n",
        "    text_to_speech(transcripcion, \"respuesta.mp3\", \"en\")\n",
        "    play_audio(\"respuesta.mp3\")\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Espera a que se presione la tecla espacio para comenzar la grabación\n",
        "    print(\"Presiona y sostiene la tecla espacio para comenzar a grabar...\")\n",
        "    start_recording.wait()\n",
        "\n",
        "    # Captura el audio del micrófono\n",
        "    with sr.Microphone() as source:\n",
        "        # print(\"Capturando audio... suelta espacio para parar\")\n",
        "        audio_chunks = []\n",
        "        while not stop_recording.is_set():\n",
        "            audio_chunk = recognizer.record(source, duration=0.5)\n",
        "            audio_chunks.append(audio_chunk)\n",
        "            sys.stdout.write(\"||||RECORDING||||\\r\")\n",
        "            sys.stdout.flush()\n",
        "        print(\"Captura completa.                   \")\n",
        "\n",
        "        # Reset the recording flags\n",
        "        start_recording.clear()\n",
        "        stop_recording.clear()\n",
        "\n",
        "        audio_data = sr.AudioData(b\"\".join([chunk.get_wav_data() for chunk in audio_chunks]), source.SAMPLE_RATE, source.SAMPLE_WIDTH)\n",
        "\n",
        "    # Guarda el audio capturado como un archivo WAV\n",
        "    wav_file = f\"captured_audio_{iteration % 2}.wav\"\n",
        "    with open(wav_file, \"wb\") as f:\n",
        "        f.write(audio_data.get_wav_data())\n",
        "\n",
        "    # Define el nombre del archivo MP3\n",
        "    mp3_file = f\"captured_audio_{iteration % 2}.mp3\"\n",
        "\n",
        "    # Aquí debes llamar a tu función send_audio_to_server\n",
        "    threading.Thread(target=send_audio_to_server, args=(mp3_file, wav_file)).start()\n",
        "\n",
        "    # Incrementa el contador de iteraciones\n",
        "    iteration += 1\n",
        "\n",
        "    # Sal del bucle si se ha establecido la bandera de salida\n",
        "    if exit_flag.is_set():\n",
        "        break\n",
        "EOL\n",
        "\n",
        "\n",
        "# Crea el archivo cliente.sh a partir de un archivo HERE\n",
        "cat <<EOL > cliente.sh\n",
        "# Activa el nuevo entorno\n",
        "conda activate IA\n",
        "python cliente.py \\$1\n",
        "EOL\n",
        "\n",
        "chmod a+x cliente.sh\n",
        "# Imprime el mensaje final\n",
        "echo \"Todo está listo para ejecutarse. Solo tienes que ejecutar el comando [python cliente.py]\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiHYBmC7aK7o"
      },
      "source": [
        "Descargar y ejecutar: \"source instalador.sh\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "q-Ln7NxzZ9Jn",
        "outputId": "35073e05-bbcf-4cfa-b411-556e95b9b681"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9337d026-3125-48c6-bdc3-57682f03cf31\", \"instalador.sh\", 5303)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ejecuta 'source instalador.sh'\n",
            "y una vez instalado el cliente ya puedes ejecutarlo como './cliente.sh http://javiergimenez.es:61468/transcribe'\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('instalador.sh')\n",
        "\n",
        "print(\"ejecuta 'source instalador.sh'\")\n",
        "!echo \"y una vez instalado el cliente ya puedes ejecutarlo como 'source cliente.sh http://javiergimenez.es:{puertoLLM}/transcribe'\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcCxu02CgZj0"
      },
      "source": [
        "# Ejecución (ejecutar siempre después de iniciar el cuaderno)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahyT-J_BgcnO",
        "outputId": "369be490-e5b0-4c7d-93e3-174f85fd9c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Para linux tipo debian, ejecuta el fichero descargado para instalar el cliente: 'source instalador.sh'\n",
            "y una vez instalado el cliente ya puedes ejecutarlo como 'source cliente.sh http://javiergimenez.es:61468/transcribe'\n"
          ]
        }
      ],
      "source": [
        "print(\"Para linux tipo debian, ejecuta el fichero descargado para instalar el cliente: 'source instalador.sh'\")\n",
        "!echo \"y una vez instalado el cliente ya puedes ejecutarlo como 'source cliente.sh http://javiergimenez.es:{puertoLLM}/transcribe'\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHSJh3QfT6Tn"
      },
      "source": [
        "# Explicación del cuaderno paso por paso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yon0x6xvpBOd"
      },
      "source": [
        "## Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ea2583eb364428a90e1eaad816b7236",
            "bc179148a83e4b78b7507e7024c14ab1",
            "394855db6734415096204aa1851fc776",
            "8f4285958e984315b322966b98234229",
            "247e2f54445944e3addf8b5f04f055a0",
            "ddbfd8e584e747ab973a71e4963f99ef",
            "8364c18cf87942c59fe410aa4b9ccae7",
            "e91de64eac204415bbc4b28b1a78999a",
            "7fca82e3afcc405383ef9659f646e590",
            "24306ef161254fd3ac72176b61098624",
            "68f22c175f8c45e992e4321e74086db9",
            "e19dc6d55f834fa9b1e47aade04a419e",
            "e36cdebbdd68454787064f337adc7c74",
            "42b45182e83d497e9ef9b74d9c1e89ca",
            "b7d06149af504b1bb4a7b19d097f3ba8",
            "7336695ae64d4befb8eec2f3f5f9e187",
            "3f2f4447180a4c39b629f88d6e43511c",
            "d61b83671bd243048eab3bbf2365682e",
            "9138a89a7d324708b59a163bc4e45dc2",
            "a0e6ac78ad0e436eb72039a9fdba3be7",
            "387a93d8b5244340b978beceb78dd2be",
            "10f66056dade46d18f5944e370043d5c",
            "0af45012ecef4c32ae0b5dc440ba71c9",
            "83b68673b78149f2bc1bb1e160bea2c4",
            "d7df2e9747c84b46900ad6a7b6f45c8a",
            "dc8784359bc9448fbe5e8e43c1e22039",
            "e027778728674552b16373b81e9eea6e",
            "9b4cf5cbe3c94d2b91ff88f66b0610a6",
            "d2ce0cfa31344cc9b571a6cedffd96f4",
            "01ee82078b454befb79adfa0488fce00",
            "8a4340d548b54add9aa7837e777f1e6e",
            "973450a8e370485891686fe6757fb5f7",
            "00b264b8165f41da8c62f654924f6b78",
            "00c37db7c5dc45b9ba88799d4b1323c4",
            "d4d3b0a29a874112b716d50b72a239cd",
            "463a59de05e546a6bc9e45361892bf00",
            "0eede775d3d84c6288b6369498734edd",
            "262314ad2df640a58e936a36e009844d",
            "df78e0d9b3b34ee7bf82fbfb2f2af4fd",
            "b1a7365f33f045a39661c78810d8cb3b",
            "4dffc0dea2134d618eb0abf6793dd555",
            "8519c53ae7ee47a8b5ff5d24aaaa53a0",
            "bcd88ac08bef41568cd46d15258a964a",
            "257af407dadd4e2eaa1f9568777d2878",
            "b1f3e5b4f7e1427eaa3078c149c47f27",
            "0d596400094a4a478d5fc985dd463af1",
            "18e18d4e516b49a4bb82b6e2295c0065",
            "de88f9bb25fc438894eaff7db49df558",
            "d82fdccbcb65489bbf6395d1a957f78b",
            "d7115422438b4acb9f42279e660212ea",
            "8cb3176ba40e46d9b5e04f1130fb1951",
            "3862d5e911aa4ac4ac11d7b1114ffa3b",
            "5b7f5d60b5ef4a45a995dcf2d9a0cd9d",
            "25401ebf1f6b459e9b1036a4c48b6b14",
            "df0c081c4d284d1a9c688578ed1f583a",
            "a983d2daba8c4fbe976fa1a68bd1f01e",
            "9d6632f37d1342f8944018ce6de94e97",
            "c9df28dadab04b44a14315b10eee5878",
            "6d5062bd941149c1b7e52e66dfa862f4",
            "0026b6e51570437c9160acbb9224df26",
            "1b4f8e85323c45bca7e641c69ea6ede0",
            "7f3e715b70c149c6aa69567bae9f7348",
            "bf90e2684f3f435b92663861414408e9",
            "3363a59ff8ae40c2ba9bb3324c6d734a",
            "54af473a30cc4de9806297c6a2cb4828",
            "b63684a40a354ac19943c4182900acb8",
            "eed653a7bbe4409ca320a307b9477653",
            "141649a807dc43c7a8135bf2d248410f",
            "ea2174db1d234519985fa7d157f3449a",
            "b0a798996bf143a39cbc6c779bca2076",
            "13c39e293efb4e9f95d769c864f5ba91",
            "7fcfc7e40e1c4a58bf32ef4c56e5cdb3",
            "ea7dd2a888e4429c8cf657c4499f7305",
            "68076c2a587a4f6b901410b61503a986",
            "ccc892cd342d4090a01854a7163b8d62",
            "6082a1ce8f7f43128cc500556623aa03",
            "c3b8ed21444b496992108818cd1266a4",
            "5aff100f5f0d4feeb3abcbedf0932c53",
            "59c1258a24c841d98d7c8eb1bb847c66",
            "c218e7477d5d4ee18a5527859d150a60",
            "67cb3f62e23d4aada358e45583eb548b",
            "bd8591a467774a9fba4c4b57d5acb726",
            "c2448d90215a4f5fb8b28656566d99be",
            "db401dee28a443708b8332e15b953961",
            "8057fba7939e4033a65e45723eddff2e",
            "1873551892904eb9811c10da7c8e7415",
            "9024894e1e524889b3ffd7566dabeeb5",
            "c2a83c87c9f749f0b44f61690e527291",
            "def3723e317d44ccb88136a947245742",
            "7249c5013f324b12999602498f2b6dd2",
            "34b16d31f19e41688b4b4e21a6cf8415",
            "c8f0af1fd8cb49c296066231ddaf87b1",
            "fe1ab9eb114e4d1fb7ad7cfb96e3a188",
            "c4c0a221a17f4806b152fdca4e7e8794",
            "e8209af2159a463cb08526169b8b82f5",
            "245b5cbade0a48c9a78c470c3a0e7966",
            "71f2bf5311fe41dfba09e640d89df6e7",
            "b45e219c17df495096a4a94514ca70fe",
            "33502d7a5d324b26b835f8d555ae8e29",
            "743feeaa4aef45679afd6eee22bc3d11",
            "9d4c97b487044c9f872974bf5bd16214",
            "439234240f864f718329158c9a920f9b",
            "2f2f17a67a3047e5a3499929f0ed73fc",
            "bed8cf05a38245fcad176f9d3dbff95c",
            "aed5ba38874545dfa99e16070b265037",
            "cf5acf00be3c4ac7bd234e36d046431e",
            "6b7b67a37bcb42028d2d61fe38847df2",
            "b38d01c11f2a48b08701fe256ba5cfea",
            "065754ce3a2943f69ba8178868574738",
            "1e83e59c1fc849acb3b95e9aefd056cb",
            "0bec91ff162b4fe2b9449bdb3de05ed9",
            "fdf3dace2605411a9a1f8a8be48336ba",
            "1e734617613d4af298c8f79e7c0fb5e8",
            "6519798715af4d78bdc59935cc4db04e",
            "1563a7cf36734735b48adec834b8f76e",
            "d8a3a1db2bfc4063bb03356f9accb164",
            "16cccf7af037468aace0d555c81c1969",
            "4ed42a7c971d44839d3cb2b94ffe5576",
            "a1d5916e3e7b4ca88a88297985dbbcd3",
            "575afac82ac8414f92d86feac3a52b6c",
            "c19911ed6bc04ea7acd701bebc1bdbe5"
          ]
        },
        "id": "SCrlkY0kLtCJ",
        "outputId": "60516cf2-c7cc-4fa4-b2f2-415597bb6142"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ea2583eb364428a90e1eaad816b7236",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e19dc6d55f834fa9b1e47aade04a419e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_phi.py:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n",
            "- configuration_phi.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0af45012ecef4c32ae0b5dc440ba71c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_phi.py:   0%|          | 0.00/33.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n",
            "- modeling_phi.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00c37db7c5dc45b9ba88799d4b1323c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.84G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1f3e5b4f7e1427eaa3078c149c47f27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a983d2daba8c4fbe976fa1a68bd1f01e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eed653a7bbe4409ca320a307b9477653",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aff100f5f0d4feeb3abcbedf0932c53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "def3723e317d44ccb88136a947245742",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "743feeaa4aef45679afd6eee22bc3d11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bec91ff162b4fe2b9449bdb3de05ed9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def print_prime(n):\n",
            "   \"\"\"\n",
            "   Print all primes between 1 and n\n",
            "   \"\"\"\n",
            "   primes = []\n",
            "   for num in range(2, n+1):\n",
            "       is_prime = True\n",
            "       for i in range(2, int(num**0.5)+1):\n",
            "           if num % i == 0:\n",
            "               is_prime = False\n",
            "               break\n",
            "       if is_prime:\n",
            "           primes.append(num)\n",
            "   print(primes)\n",
            "\n",
            "print_prime(20)\n",
            "```\n",
            "\n",
            "## Exercises\n",
            "\n",
            "1. Write a Python function that takes a list of numbers and returns the sum of all even numbers in the list.\n",
            "\n",
            "```python\n",
            "def sum_even(numbers):\n",
            "   \"\"\"\n",
            "   Returns the sum of all even numbers in the list\n",
            "   \"\"\"\n",
            "   return sum(num for num in numbers if\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "torch.set_default_device('cuda')\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "inputs = tokenizer('''```python\n",
        "def print_prime(n):\n",
        "   \"\"\"\n",
        "   Print all primes between 1 and n\n",
        "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVBTBFAuWsd1",
        "outputId": "507eb881-0204-4fe3-b142-928835050076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Translate next phrase to spanish:\n",
            "\"Generating interview questions: For each paragraph, we construct an artificial interview scenario where an LLM plays the role of an interviewer, generating questions that elicit responses naturally fitting the given paragraph from the book. The goal is to stimulate an insightful dialogue, giving the impression that Bourdain himself is answering questions about his life and experiences.\"\n",
            "\n",
            "Exercise: Translate the following sentence into Spanish:\n",
            "\"Generating interview questions: For each paragraph, we construct an artificial interview scenario where an LLM plays the role of an interviewer, generating questions that elicit responses naturally fitting the given paragraph from the book. The goal is to stimulate an insightful dialogue, giving the impression that Bourdain himself is answering questions about his life and experiences.\"\n",
            "\n",
            "Answer: \"Generar interviewes para las parámetros: En cada página, se construye una conversación artificial que se aplica a un LLM, que se construye una conversación que se aplica a una persona que está en el book. El objetivo es que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book, que se aplica a una conversación que se aplica a una persona que está en el book\n"
          ]
        }
      ],
      "source": [
        "# traduce muy mal\n",
        "inputs = tokenizer('''\n",
        "Translate next phrase to spanish:\n",
        "\"Generating interview questions: For each paragraph, we construct an artificial interview scenario where an LLM plays the role of an interviewer, generating questions that elicit responses naturally fitting the given paragraph from the book. The goal is to stimulate an insightful dialogue, giving the impression that Bourdain himself is answering questions about his life and experiences.\"\n",
        "''', return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=500)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbrs6WPOpOK9"
      },
      "source": [
        "## chateando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuaQZsnzMEqn",
        "outputId": "22ecf405-29ab-4a03-85b2-352890dc5ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Contexto, Alice is a high school teacher, she like play tennis and watch television. This is the firs time Alice and Bob meet.\n",
            "Bob: Hi! whats your name?\n",
            "\n",
            "Alice: Hi Bob, I'm Alice. Nice to meet you.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Contexto, Alice is a high school teacher, she like play tennis and watch television. This is the firs time Alice and Bob meet.\n",
        "Bob: Hi! whats your name?\n",
        "\n",
        "Alice:\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "input_length = inputs[\"input_ids\"].size(1)  # Obtén el número de tokens en la entrada\n",
        "\n",
        "max_additional_tokens = 50  # Establece tu límite para el número de tokens adicionales aquí\n",
        "\n",
        "def find_nth_occurrence(string, substring, n):\n",
        "    start = 0\n",
        "    for _ in range(n):\n",
        "        start = string.find(substring, start) + 1\n",
        "        if start == 0:\n",
        "            return -1\n",
        "    return start - 1\n",
        "\n",
        "# Generar texto normalmente sin usar early_stopping para la cadena\n",
        "outputs = model.generate(**inputs, max_length=input_length + max_additional_tokens)\n",
        "\n",
        "# Decodificar el texto generado\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Encuentra la n-ésima ocurrencia de \"Alice:\"\n",
        "n = 2  # Cambia este valor para encontrar una ocurrencia diferente\n",
        "stop_index = find_nth_occurrence(generated_text, \"Bob:\", n)\n",
        "\n",
        "# Si encontramos la n-ésima ocurrencia, cortamos el texto en ese punto\n",
        "if stop_index != -1:\n",
        "    generated_text = generated_text[:stop_index]\n",
        "\n",
        "print(generated_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubfbIxxcSrtA",
        "outputId": "7e677395-b113-4b93-ebc8-2cf594244e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Contexto, Alice is a high school teacher, she like play tennis and watch television. This is the firs time Alice and Bob meet.\n",
            "Bob: Hi! whats your name?\n",
            "\n",
            "Alice: Hi Bob, I'm Alice. Nice to meet you.\n",
            "\n",
            "Bob: what do you do for a living?\n",
            "\n",
            "Alice: I'm a high school teacher.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Contexto, Alice is a high school teacher, she like play tennis and watch television. This is the firs time Alice and Bob meet.\n",
        "Bob: Hi! whats your name?\n",
        "\n",
        "Alice: Hi Bob, I'm Alice. Nice to meet you.\n",
        "\n",
        "Bob: what do you do for a living?\n",
        "\n",
        "Alice:\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "input_length = inputs[\"input_ids\"].size(1)  # Obtén el número de tokens en la entrada\n",
        "\n",
        "def find_nth_occurrence(string, substring, n):\n",
        "    start = 0\n",
        "    for _ in range(n):\n",
        "        start = string.find(substring, start) + 1\n",
        "        if start == 0:\n",
        "            return -1\n",
        "    return start - 1\n",
        "\n",
        "# Generar texto normalmente sin usar early_stopping para la cadena\n",
        "outputs = model.generate(**inputs, max_length=input_length + max_additional_tokens)\n",
        "\n",
        "# Decodificar el texto generado\n",
        "generated_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "# Encuentra la n-ésima ocurrencia de \"Alice:\"\n",
        "n = 3  # Cambia este valor para encontrar una ocurrencia diferente\n",
        "stop_index = find_nth_occurrence(generated_text, \"Bob:\", n)\n",
        "\n",
        "# Si encontramos la n-ésima ocurrencia, cortamos el texto en ese punto\n",
        "if stop_index != -1:\n",
        "    generated_text = generated_text[:stop_index]\n",
        "\n",
        "print(generated_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh4yJGFcpW8v"
      },
      "source": [
        "## Servidor multihilo para chatear con celebridades novelescas (paso por paso ver el funcionamiento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "golQsQ92pcOv",
        "outputId": "72b60aab-52ef-4e2e-d36e-a7cf8473e432"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha795ZC0qSWU"
      },
      "source": [
        "Cargar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-VMgVcIph8f",
        "outputId": "e3ed199b-e66e-4513-a002-94709d59a06a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Contexto, Alice is a high school teacher, she like play tennis and watch television. This is the firs time Alice and Bob meet.\n",
            "Bob: Hi! whats your name?\n",
            "\n",
            "Alice: Hi Bob, I'm Alice. Nice to meet you.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "torch.set_default_device('cuda')\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "\n",
        "prompt = \"\"\"\n",
        "Contexto, Alice is a high school teacher, she like play tennis and watch television. This is the firs time Alice and Bob meet.\n",
        "Bob: Hi! whats your name?\n",
        "\n",
        "Alice:\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "input_length = inputs[\"input_ids\"].size(1)  # Obtén el número de tokens en la entrada\n",
        "\n",
        "max_additional_tokens = 50  # Establece tu límite para el número de tokens adicionales aquí\n",
        "\n",
        "def find_nth_occurrence(string, substring, n):\n",
        "    start = 0\n",
        "    for _ in range(n):\n",
        "        start = string.find(substring, start) + 1\n",
        "        if start == 0:\n",
        "            return -1\n",
        "    return start - 1\n",
        "\n",
        "# Generar texto normalmente sin usar early_stopping para la cadena\n",
        "outputs = model.generate(**inputs, max_length=input_length + max_additional_tokens)\n",
        "\n",
        "# Decodificar el texto generado\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Encuentra la n-ésima ocurrencia de \"Alice:\"\n",
        "n = 2  # Cambia este valor para encontrar una ocurrencia diferente\n",
        "stop_index = find_nth_occurrence(generated_text, \"Bob:\", n)\n",
        "\n",
        "# Si encontramos la n-ésima ocurrencia, cortamos el texto en ese punto\n",
        "if stop_index != -1:\n",
        "    generated_text = generated_text[:stop_index]\n",
        "\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV5-PCB_qdEe"
      },
      "source": [
        "modelo whisper (para transcribir de la voz del usuario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp7vhscnqcK-"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "modelWhisper = whisper.load_model('medium')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6KR-8-vqVU5"
      },
      "source": [
        "Servidor multihilo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jf8ThqpQ6tq",
        "outputId": "f123c769-2941-4f5c-a81d-3d1de1851f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5500\n",
            " * Running on http://172.28.0.12:5500\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:33:57] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "Bob: Wow, that's amazing!\n",
            "King Arthur: Yes, I am. What brings you here?\n",
            "Bob: I am a commoner, and I wanted to talk to you about the importance of\n",
            "n: 2\n",
            "generated_text:  I am the king of England.\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:34:10] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "Bob: What is Merlin?\n",
            "King Arthur: Merlin is a magical being who helps me make important decisions.\n",
            "\n",
            "Bob: Can you give me an example of when you used Merlin's help?\n",
            "King\n",
            "n: 3\n",
            "generated_text:  My best advisor is Merlin.\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:34:27] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he has a lot of knowledge and experience.\n",
            "\n",
            "Bob: What is your favorite color?\n",
            "King Arthur: My favorite color is blue.\n",
            "\n",
            "n: 4\n",
            "generated_text:  Yes, he is.\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:34:36] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "Bob: is the sun a star?\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "Bob: is the moon a planet?\n",
            "King Arthur: No, it is not.\n",
            "\n",
            "\n",
            "Bob: is the\n",
            "n: 5\n",
            "generated_text:  Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:35:12] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "Bob: What is the difference between a king and a queen?\n",
            "King Arthur: A king is the head of the state, while a queen is the head of the country.\n",
            "\n",
            "\n",
            "\n",
            "Bob\n",
            "n: 6\n",
            "generated_text:  Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:35:31] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "Bob: That's impressive.\n",
            "King Arthur: Yes, he is. He can also communicate with animals.\n",
            "\n",
            "Bob: Really?\n",
            "King Arthur: Yes, he can\n",
            "n: 7\n",
            "generated_text:  Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:36:12] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "Bob: That's amazing.\n",
            "\n",
            "\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: I wish I could be as smart as\n",
            "n: 8\n",
            "generated_text:  He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:37:47] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "Bob: She is the witch who lives in the forest. She is jealous of your power and wants to steal it.\n",
            "\n",
            "\n",
            "\n",
            "Bob: How can you stop her?\n",
            "King Arthur: I have a\n",
            "n: 9\n",
            "generated_text:  Morgana? Who is she?\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:38:07] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "Bob: She is a witch who wants to steal the magic from you.\n",
            "King Arthur: Oh, no! That is terrible! How can she do that?\n",
            "\n",
            "Bob: She can use her magic to\n",
            "n: 10\n",
            "generated_text:  Dangerous? How so?\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:38:28] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "Bob: She is Morgana, the witch who lives in the forest. She is jealous of you and your power.\n",
            "\n",
            "\n",
            "King Arthur: Oh, I see. Well, I don't want\n",
            "n: 11\n",
            "generated_text:  Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:39:05] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "Bob: Because she is jealous of you!\n",
            "King Arthur: Jealous? How?\n",
            "\n",
            "\n",
            "\n",
            "Bob: Because you are the king and she is not!\n",
            "King Arthur: That is not true!\n",
            "n: 12\n",
            "generated_text:  Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:39:40] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "Bob: I'm trying to save you!\n",
            "King Arthur: Save me? How?\n",
            "\n",
            "\n",
            "\n",
            "Bob: I'm using my magic!\n",
            "King Arthur: Magic? What magic?\n",
            "\n",
            "\n",
            "n: 13\n",
            "generated_text:  Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:40:18] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She is a dragon and she is hungry!\n",
            "King Arthur: Hungry? What is she hungry for?\n",
            "\n",
            "\n",
            "\n",
            "Bob: Her scales!\n",
            "King Arthur: Scales? What are they for\n",
            "n: 14\n",
            "generated_text:  Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:40:30] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "Bob: It means we are nervous and scared.\n",
            "\n",
            "\n",
            "\n",
            "King Arthur: Nervous and scared? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Because we are cornered by Morgana and her\n",
            "n: 15\n",
            "generated_text:  Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:40:59] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: I am a commoner.\n",
            "King Arthur: I am a king.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: I am sorry, but I cannot believe you.\n",
            "King Arthur: I am sorry,\n",
            "n: 16\n",
            "generated_text:  I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:41:13] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur: Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: She is a witch!\n",
            "King Arthur: Witch? How do you know?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "n: 17\n",
            "generated_text:  Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Exception on /transcribe [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 59, in load_audio\n",
            "    out = run(cmd, capture_output=True, check=True).stdout\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'received_audio_1695199372884.mp3', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-44-7625412cfdad>\", line 54, in transcribe_audio\n",
            "    transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=\"en\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 121, in transcribe\n",
            "    mel = log_mel_spectrogram(audio, padding=N_SAMPLES)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 140, in log_mel_spectrogram\n",
            "    audio = load_audio(audio)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 61, in load_audio\n",
            "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
            "RuntimeError: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "[mp3 @ 0x58660e1ea180] Format mp3 detected only with low score of 1, misdetection possible!\n",
            "[mp3 @ 0x58660e1ea180] Failed to read frame size: Could not seek to 1026.\n",
            "received_audio_1695199372884.mp3: Invalid argument\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:42:52] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
            "ERROR:__main__:Exception on /transcribe [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 59, in load_audio\n",
            "    out = run(cmd, capture_output=True, check=True).stdout\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'received_audio_1695199375603.mp3', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-44-7625412cfdad>\", line 54, in transcribe_audio\n",
            "    transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=\"en\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 121, in transcribe\n",
            "    mel = log_mel_spectrogram(audio, padding=N_SAMPLES)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 140, in log_mel_spectrogram\n",
            "    audio = load_audio(audio)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 61, in load_audio\n",
            "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
            "RuntimeError: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "[mp3 @ 0x5b0036989180] Format mp3 detected only with low score of 1, misdetection possible!\n",
            "[mp3 @ 0x5b0036989180] Failed to read frame size: Could not seek to 1026.\n",
            "received_audio_1695199375603.mp3: Invalid argument\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:42:55] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
            "ERROR:__main__:Exception on /transcribe [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 59, in load_audio\n",
            "    out = run(cmd, capture_output=True, check=True).stdout\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'received_audio_1695199385743.mp3', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-44-7625412cfdad>\", line 54, in transcribe_audio\n",
            "    transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=\"en\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 121, in transcribe\n",
            "    mel = log_mel_spectrogram(audio, padding=N_SAMPLES)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 140, in log_mel_spectrogram\n",
            "    audio = load_audio(audio)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 61, in load_audio\n",
            "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
            "RuntimeError: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "[mp3 @ 0x5c1aa6c45180] Format mp3 detected only with low score of 1, misdetection possible!\n",
            "[mp3 @ 0x5c1aa6c45180] Failed to read frame size: Could not seek to 1026.\n",
            "received_audio_1695199385743.mp3: Invalid argument\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:43:05] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
            "ERROR:__main__:Exception on /transcribe [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 59, in load_audio\n",
            "    out = run(cmd, capture_output=True, check=True).stdout\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'received_audio_1695199388396.mp3', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-44-7625412cfdad>\", line 54, in transcribe_audio\n",
            "    transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=\"en\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 121, in transcribe\n",
            "    mel = log_mel_spectrogram(audio, padding=N_SAMPLES)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 140, in log_mel_spectrogram\n",
            "    audio = load_audio(audio)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 61, in load_audio\n",
            "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
            "RuntimeError: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "[mp3 @ 0x5a7dabd76180] Format mp3 detected only with low score of 1, misdetection possible!\n",
            "[mp3 @ 0x5a7dabd76180] Failed to read frame size: Could not seek to 1026.\n",
            "received_audio_1695199388396.mp3: Invalid argument\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:43:08] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur: Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Hi, how are you?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:47:40] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur: Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Hi, how are you?\n",
            "King Arthur: I am fine, thank you.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: I am here to help you.\n",
            "King Arthur: Help me? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: I am a messenger from the neighboring kingdom.\n",
            "King Arthur: Messenger?\n",
            "n: 18\n",
            "generated_text:  I am fine, thank you.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "prompt: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur: Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Hi, how are you?\n",
            "King Arthur: I am fine, thank you.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Sep/2023 08:47:53] \"POST /transcribe HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_generated_text: Context: Bob, a commoner, talk alone with King Arthur.\n",
            "\n",
            "Bob: Hi, who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "Bob: Who is your best advisor?\n",
            "King Arthur: My best advisor is Merlin.\n",
            "\n",
            "\n",
            "Bob: is Merlin a good advisor?\n",
            "King Arthur: Yes, he is.\n",
            "\n",
            "\n",
            "Bob: light\n",
            "King Arthur: Yes, it is.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Why do you think so?\n",
            "King Arthur: Because he is wise and knowledgeable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Give me some examples about his ways.\n",
            "King Arthur: Well, he is a skilled wizard and can cast spells.\n",
            "\n",
            "\n",
            "Bob: What kind of spells he can cast?\n",
            "King Arthur: He can cast spells to heal the sick, to protect the kingdom, and to bring rain.\n",
            "\n",
            "\n",
            "\n",
            "Bob: Beware! Morgana is here!\n",
            "King Arthur: Morgana? Who is she?\n",
            "\n",
            "Bob: You have sister? She is dangerous.\n",
            "King Arthur: Dangerous? How so?\n",
            "\n",
            "\n",
            "Bob: see is a witch and see like you death\n",
            "King Arthur: Death? What are you talking about?\n",
            "\n",
            "\n",
            "\n",
            "Bob: She wants to kill you!\n",
            "King Arthur: Kill me? Why?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Let's run! See, throw us arrows!\n",
            "King Arthur: Arrows? What are you doing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Mordana is attack us!\n",
            "King Arthur: Attack us? How?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Now nous penchonssuspenseful\n",
            "King Arthur: Suspenseful? What is that?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur: Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Hi, how are you?\n",
            "King Arthur: I am fine, thank you.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: Who are you?\n",
            "King Arthur: I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: You are in danger!\n",
            "King Arthur: Danger? What is it?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bob: I am a spy!\n",
            "King Arthur: Spy? What are you doing?\n",
            "n: 19\n",
            "generated_text:  I am the king of England.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from threading import Lock\n",
        "import torch\n",
        "\n",
        "import time\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de transcribir\n",
        "transcribe_lock = Lock()\n",
        "\n",
        "# Crea un bloqueo para proteger el código contra la concurrencia a la hora de generar texto\n",
        "generate_lock = Lock()\n",
        "\n",
        "# ai = \"Alice:\"\n",
        "# user = \"Bob:\"\n",
        "\n",
        "# historico = f\"Contexto, {ai} is a high school teacher, she like play tennis and watch television. This is the firs time {ai} and {user} meet.\\n\"\n",
        "\n",
        "iteracion = 0\n",
        "\n",
        "ai = \"King Arthur\"\n",
        "user = \"Bob\"\n",
        "\n",
        "historico = f\"Context: {user}, a commoner, talk alone with {ai}.\\n\"\n",
        "\n",
        "@app.route('/transcribe', methods=['POST'])\n",
        "def transcribe_audio():\n",
        "    global historico\n",
        "    global user\n",
        "    global ai\n",
        "    global iteracion\n",
        "\n",
        "    # Comprueba si el archivo fue enviado\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify(error=\"No file part\"), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    # Comprueba si el usuario no seleccionó un archivo\n",
        "    if file.filename == '':\n",
        "        return jsonify(error=\"No selected file\"), 400\n",
        "\n",
        "    # Genera un nombre de archivo único utilizando una marca de tiempo\n",
        "    timestamp = int(time.time() * 1000)  # Marca de tiempo en milisegundos\n",
        "    mp3_filepath = f\"received_audio_{timestamp}.mp3\"\n",
        "    file.save(mp3_filepath)\n",
        "\n",
        "    # Transcribe el archivo MP3 (Asegúrate de tener el modelo cargado correctamente)\n",
        "    # Transcribe el archivo MP3 dentro de una sección crítica protegida por un bloqueo\n",
        "    with transcribe_lock:\n",
        "        # transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False)\n",
        "        # transcipción lenguaje inglés\n",
        "        transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False, language=\"en\")\n",
        "        transcripcion = transcripcion[\"text\"]\n",
        "\n",
        "    prompt = f\"{historico}\\n{user}:{transcripcion}\\n{ai}:\"\n",
        "    print(\"prompt:\", prompt)\n",
        "\n",
        "\n",
        "    # Asegúrate de que tanto el modelo como los inputs están en el dispositivo GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    with generate_lock:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "\n",
        "        input_length = inputs[\"input_ids\"].size(1)  # Obtén el número de tokens en la entrada\n",
        "\n",
        "        max_additional_tokens = 50  # Establece tu límite para el número de tokens adicionales aquí\n",
        "        # Generar texto normalmente sin usar early_stopping para la cadena\n",
        "        outputs = model.generate(**inputs, max_length=input_length + max_additional_tokens)\n",
        "\n",
        "        # Decodificar el texto generado\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        print(\"output_generated_text:\", generated_text)\n",
        "\n",
        "        # Encuentra la n-ésima ocurrencia del nombre que tenga ai\n",
        "        n = iteracion + 2  # Cambia este valor para encontrar una ocurrencia diferente\n",
        "        print(\"n:\", n)\n",
        "        start_index = find_nth_occurrence(generated_text, f\"{ai}:\", n-1) + len(f\"{ai}:\")\n",
        "        stop_index = find_nth_occurrence(generated_text, f\"{user}:\", n)\n",
        "        # si no genera respuesta ficticia de usuario cortamos en el primer salto de linea\n",
        "        if stop_index == -1:\n",
        "            stop_index =  generated_text.find(\"\\n\", start_index) - 1\n",
        "\n",
        "        # Si encontramos la n-ésima ocurrencia, cortamos el texto en ese punto\n",
        "        if stop_index != -1:\n",
        "            historico = generated_text[:stop_index]\n",
        "            generated_text = generated_text[start_index:stop_index]\n",
        "\n",
        "        print(\"generated_text:\", generated_text)\n",
        "        iteracion += 1\n",
        "    # # Devuelve la transcripción\n",
        "    return jsonify(transcripcion=generated_text)\n",
        "    # Devuelve la transcripción\n",
        "    # return jsonify(transcripcion={\"text\": transcripcion})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5500, threaded=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0026b6e51570437c9160acbb9224df26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b264b8165f41da8c62f654924f6b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00c37db7c5dc45b9ba88799d4b1323c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4d3b0a29a874112b716d50b72a239cd",
              "IPY_MODEL_463a59de05e546a6bc9e45361892bf00",
              "IPY_MODEL_0eede775d3d84c6288b6369498734edd"
            ],
            "layout": "IPY_MODEL_262314ad2df640a58e936a36e009844d"
          }
        },
        "01ee82078b454befb79adfa0488fce00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "065754ce3a2943f69ba8178868574738": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af45012ecef4c32ae0b5dc440ba71c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83b68673b78149f2bc1bb1e160bea2c4",
              "IPY_MODEL_d7df2e9747c84b46900ad6a7b6f45c8a",
              "IPY_MODEL_dc8784359bc9448fbe5e8e43c1e22039"
            ],
            "layout": "IPY_MODEL_e027778728674552b16373b81e9eea6e"
          }
        },
        "0bec91ff162b4fe2b9449bdb3de05ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdf3dace2605411a9a1f8a8be48336ba",
              "IPY_MODEL_1e734617613d4af298c8f79e7c0fb5e8",
              "IPY_MODEL_6519798715af4d78bdc59935cc4db04e"
            ],
            "layout": "IPY_MODEL_1563a7cf36734735b48adec834b8f76e"
          }
        },
        "0d596400094a4a478d5fc985dd463af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7115422438b4acb9f42279e660212ea",
            "placeholder": "​",
            "style": "IPY_MODEL_8cb3176ba40e46d9b5e04f1130fb1951",
            "value": "generation_config.json: 100%"
          }
        },
        "0eede775d3d84c6288b6369498734edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcd88ac08bef41568cd46d15258a964a",
            "placeholder": "​",
            "style": "IPY_MODEL_257af407dadd4e2eaa1f9568777d2878",
            "value": " 2.84G/2.84G [00:32&lt;00:00, 41.5MB/s]"
          }
        },
        "10f66056dade46d18f5944e370043d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c39e293efb4e9f95d769c864f5ba91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141649a807dc43c7a8135bf2d248410f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fcfc7e40e1c4a58bf32ef4c56e5cdb3",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7dd2a888e4429c8cf657c4499f7305",
            "value": "vocab.json: 100%"
          }
        },
        "1563a7cf36734735b48adec834b8f76e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16cccf7af037468aace0d555c81c1969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1873551892904eb9811c10da7c8e7415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18e18d4e516b49a4bb82b6e2295c0065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3862d5e911aa4ac4ac11d7b1114ffa3b",
            "max": 69,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b7f5d60b5ef4a45a995dcf2d9a0cd9d",
            "value": 69
          }
        },
        "1b4f8e85323c45bca7e641c69ea6ede0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e734617613d4af298c8f79e7c0fb5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed42a7c971d44839d3cb2b94ffe5576",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1d5916e3e7b4ca88a88297985dbbcd3",
            "value": 99
          }
        },
        "1e83e59c1fc849acb3b95e9aefd056cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24306ef161254fd3ac72176b61098624": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245b5cbade0a48c9a78c470c3a0e7966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247e2f54445944e3addf8b5f04f055a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25401ebf1f6b459e9b1036a4c48b6b14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257af407dadd4e2eaa1f9568777d2878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "262314ad2df640a58e936a36e009844d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2f17a67a3047e5a3499929f0ed73fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065754ce3a2943f69ba8178868574738",
            "placeholder": "​",
            "style": "IPY_MODEL_1e83e59c1fc849acb3b95e9aefd056cb",
            "value": " 1.08k/1.08k [00:00&lt;00:00, 21.9kB/s]"
          }
        },
        "33502d7a5d324b26b835f8d555ae8e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3363a59ff8ae40c2ba9bb3324c6d734a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34b16d31f19e41688b4b4e21a6cf8415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_245b5cbade0a48c9a78c470c3a0e7966",
            "max": 2114924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71f2bf5311fe41dfba09e640d89df6e7",
            "value": 2114924
          }
        },
        "3862d5e911aa4ac4ac11d7b1114ffa3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387a93d8b5244340b978beceb78dd2be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394855db6734415096204aa1851fc776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91de64eac204415bbc4b28b1a78999a",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fca82e3afcc405383ef9659f646e590",
            "value": 727
          }
        },
        "3f2f4447180a4c39b629f88d6e43511c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b45182e83d497e9ef9b74d9c1e89ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9138a89a7d324708b59a163bc4e45dc2",
            "max": 2027,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0e6ac78ad0e436eb72039a9fdba3be7",
            "value": 2027
          }
        },
        "439234240f864f718329158c9a920f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7b67a37bcb42028d2d61fe38847df2",
            "max": 1080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b38d01c11f2a48b08701fe256ba5cfea",
            "value": 1080
          }
        },
        "463a59de05e546a6bc9e45361892bf00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dffc0dea2134d618eb0abf6793dd555",
            "max": 2836621662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8519c53ae7ee47a8b5ff5d24aaaa53a0",
            "value": 2836621662
          }
        },
        "4dffc0dea2134d618eb0abf6793dd555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed42a7c971d44839d3cb2b94ffe5576": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54af473a30cc4de9806297c6a2cb4828": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575afac82ac8414f92d86feac3a52b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c1258a24c841d98d7c8eb1bb847c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2448d90215a4f5fb8b28656566d99be",
            "placeholder": "​",
            "style": "IPY_MODEL_db401dee28a443708b8332e15b953961",
            "value": "merges.txt: 100%"
          }
        },
        "5aff100f5f0d4feeb3abcbedf0932c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59c1258a24c841d98d7c8eb1bb847c66",
              "IPY_MODEL_c218e7477d5d4ee18a5527859d150a60",
              "IPY_MODEL_67cb3f62e23d4aada358e45583eb548b"
            ],
            "layout": "IPY_MODEL_bd8591a467774a9fba4c4b57d5acb726"
          }
        },
        "5b7f5d60b5ef4a45a995dcf2d9a0cd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ea2583eb364428a90e1eaad816b7236": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc179148a83e4b78b7507e7024c14ab1",
              "IPY_MODEL_394855db6734415096204aa1851fc776",
              "IPY_MODEL_8f4285958e984315b322966b98234229"
            ],
            "layout": "IPY_MODEL_247e2f54445944e3addf8b5f04f055a0"
          }
        },
        "6082a1ce8f7f43128cc500556623aa03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6519798715af4d78bdc59935cc4db04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575afac82ac8414f92d86feac3a52b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_c19911ed6bc04ea7acd701bebc1bdbe5",
            "value": " 99.0/99.0 [00:00&lt;00:00, 2.41kB/s]"
          }
        },
        "67cb3f62e23d4aada358e45583eb548b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9024894e1e524889b3ffd7566dabeeb5",
            "placeholder": "​",
            "style": "IPY_MODEL_c2a83c87c9f749f0b44f61690e527291",
            "value": " 456k/456k [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "68076c2a587a4f6b901410b61503a986": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f22c175f8c45e992e4321e74086db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b7b67a37bcb42028d2d61fe38847df2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d5062bd941149c1b7e52e66dfa862f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54af473a30cc4de9806297c6a2cb4828",
            "placeholder": "​",
            "style": "IPY_MODEL_b63684a40a354ac19943c4182900acb8",
            "value": " 237/237 [00:00&lt;00:00, 4.80kB/s]"
          }
        },
        "71f2bf5311fe41dfba09e640d89df6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7249c5013f324b12999602498f2b6dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c0a221a17f4806b152fdca4e7e8794",
            "placeholder": "​",
            "style": "IPY_MODEL_e8209af2159a463cb08526169b8b82f5",
            "value": "tokenizer.json: 100%"
          }
        },
        "7336695ae64d4befb8eec2f3f5f9e187": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "743feeaa4aef45679afd6eee22bc3d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d4c97b487044c9f872974bf5bd16214",
              "IPY_MODEL_439234240f864f718329158c9a920f9b",
              "IPY_MODEL_2f2f17a67a3047e5a3499929f0ed73fc"
            ],
            "layout": "IPY_MODEL_bed8cf05a38245fcad176f9d3dbff95c"
          }
        },
        "7f3e715b70c149c6aa69567bae9f7348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fca82e3afcc405383ef9659f646e590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fcfc7e40e1c4a58bf32ef4c56e5cdb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8057fba7939e4033a65e45723eddff2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8364c18cf87942c59fe410aa4b9ccae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83b68673b78149f2bc1bb1e160bea2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b4cf5cbe3c94d2b91ff88f66b0610a6",
            "placeholder": "​",
            "style": "IPY_MODEL_d2ce0cfa31344cc9b571a6cedffd96f4",
            "value": "modeling_phi.py: 100%"
          }
        },
        "8519c53ae7ee47a8b5ff5d24aaaa53a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4340d548b54add9aa7837e777f1e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cb3176ba40e46d9b5e04f1130fb1951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f4285958e984315b322966b98234229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24306ef161254fd3ac72176b61098624",
            "placeholder": "​",
            "style": "IPY_MODEL_68f22c175f8c45e992e4321e74086db9",
            "value": " 727/727 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "9024894e1e524889b3ffd7566dabeeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9138a89a7d324708b59a163bc4e45dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "973450a8e370485891686fe6757fb5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4cf5cbe3c94d2b91ff88f66b0610a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4c97b487044c9f872974bf5bd16214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed5ba38874545dfa99e16070b265037",
            "placeholder": "​",
            "style": "IPY_MODEL_cf5acf00be3c4ac7bd234e36d046431e",
            "value": "added_tokens.json: 100%"
          }
        },
        "9d6632f37d1342f8944018ce6de94e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4f8e85323c45bca7e641c69ea6ede0",
            "placeholder": "​",
            "style": "IPY_MODEL_7f3e715b70c149c6aa69567bae9f7348",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a0e6ac78ad0e436eb72039a9fdba3be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1d5916e3e7b4ca88a88297985dbbcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a983d2daba8c4fbe976fa1a68bd1f01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d6632f37d1342f8944018ce6de94e97",
              "IPY_MODEL_c9df28dadab04b44a14315b10eee5878",
              "IPY_MODEL_6d5062bd941149c1b7e52e66dfa862f4"
            ],
            "layout": "IPY_MODEL_0026b6e51570437c9160acbb9224df26"
          }
        },
        "aed5ba38874545dfa99e16070b265037": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a798996bf143a39cbc6c779bca2076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6082a1ce8f7f43128cc500556623aa03",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b8ed21444b496992108818cd1266a4",
            "value": " 798k/798k [00:00&lt;00:00, 14.2MB/s]"
          }
        },
        "b1a7365f33f045a39661c78810d8cb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1f3e5b4f7e1427eaa3078c149c47f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d596400094a4a478d5fc985dd463af1",
              "IPY_MODEL_18e18d4e516b49a4bb82b6e2295c0065",
              "IPY_MODEL_de88f9bb25fc438894eaff7db49df558"
            ],
            "layout": "IPY_MODEL_d82fdccbcb65489bbf6395d1a957f78b"
          }
        },
        "b38d01c11f2a48b08701fe256ba5cfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b45e219c17df495096a4a94514ca70fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b63684a40a354ac19943c4182900acb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d06149af504b1bb4a7b19d097f3ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387a93d8b5244340b978beceb78dd2be",
            "placeholder": "​",
            "style": "IPY_MODEL_10f66056dade46d18f5944e370043d5c",
            "value": " 2.03k/2.03k [00:00&lt;00:00, 29.1kB/s]"
          }
        },
        "bc179148a83e4b78b7507e7024c14ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddbfd8e584e747ab973a71e4963f99ef",
            "placeholder": "​",
            "style": "IPY_MODEL_8364c18cf87942c59fe410aa4b9ccae7",
            "value": "config.json: 100%"
          }
        },
        "bcd88ac08bef41568cd46d15258a964a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8591a467774a9fba4c4b57d5acb726": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed8cf05a38245fcad176f9d3dbff95c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf90e2684f3f435b92663861414408e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19911ed6bc04ea7acd701bebc1bdbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c218e7477d5d4ee18a5527859d150a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8057fba7939e4033a65e45723eddff2e",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1873551892904eb9811c10da7c8e7415",
            "value": 456318
          }
        },
        "c2448d90215a4f5fb8b28656566d99be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a83c87c9f749f0b44f61690e527291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b8ed21444b496992108818cd1266a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c0a221a17f4806b152fdca4e7e8794": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f0af1fd8cb49c296066231ddaf87b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45e219c17df495096a4a94514ca70fe",
            "placeholder": "​",
            "style": "IPY_MODEL_33502d7a5d324b26b835f8d555ae8e29",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 18.6MB/s]"
          }
        },
        "c9df28dadab04b44a14315b10eee5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf90e2684f3f435b92663861414408e9",
            "max": 237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3363a59ff8ae40c2ba9bb3324c6d734a",
            "value": 237
          }
        },
        "ccc892cd342d4090a01854a7163b8d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf5acf00be3c4ac7bd234e36d046431e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ce0cfa31344cc9b571a6cedffd96f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4d3b0a29a874112b716d50b72a239cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df78e0d9b3b34ee7bf82fbfb2f2af4fd",
            "placeholder": "​",
            "style": "IPY_MODEL_b1a7365f33f045a39661c78810d8cb3b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d61b83671bd243048eab3bbf2365682e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7115422438b4acb9f42279e660212ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7df2e9747c84b46900ad6a7b6f45c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ee82078b454befb79adfa0488fce00",
            "max": 33475,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a4340d548b54add9aa7837e777f1e6e",
            "value": 33475
          }
        },
        "d82fdccbcb65489bbf6395d1a957f78b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a3a1db2bfc4063bb03356f9accb164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db401dee28a443708b8332e15b953961": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8784359bc9448fbe5e8e43c1e22039": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_973450a8e370485891686fe6757fb5f7",
            "placeholder": "​",
            "style": "IPY_MODEL_00b264b8165f41da8c62f654924f6b78",
            "value": " 33.5k/33.5k [00:00&lt;00:00, 776kB/s]"
          }
        },
        "ddbfd8e584e747ab973a71e4963f99ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de88f9bb25fc438894eaff7db49df558": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25401ebf1f6b459e9b1036a4c48b6b14",
            "placeholder": "​",
            "style": "IPY_MODEL_df0c081c4d284d1a9c688578ed1f583a",
            "value": " 69.0/69.0 [00:00&lt;00:00, 819B/s]"
          }
        },
        "def3723e317d44ccb88136a947245742": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7249c5013f324b12999602498f2b6dd2",
              "IPY_MODEL_34b16d31f19e41688b4b4e21a6cf8415",
              "IPY_MODEL_c8f0af1fd8cb49c296066231ddaf87b1"
            ],
            "layout": "IPY_MODEL_fe1ab9eb114e4d1fb7ad7cfb96e3a188"
          }
        },
        "df0c081c4d284d1a9c688578ed1f583a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df78e0d9b3b34ee7bf82fbfb2f2af4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e027778728674552b16373b81e9eea6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e19dc6d55f834fa9b1e47aade04a419e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e36cdebbdd68454787064f337adc7c74",
              "IPY_MODEL_42b45182e83d497e9ef9b74d9c1e89ca",
              "IPY_MODEL_b7d06149af504b1bb4a7b19d097f3ba8"
            ],
            "layout": "IPY_MODEL_7336695ae64d4befb8eec2f3f5f9e187"
          }
        },
        "e36cdebbdd68454787064f337adc7c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2f4447180a4c39b629f88d6e43511c",
            "placeholder": "​",
            "style": "IPY_MODEL_d61b83671bd243048eab3bbf2365682e",
            "value": "configuration_phi.py: 100%"
          }
        },
        "e8209af2159a463cb08526169b8b82f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e91de64eac204415bbc4b28b1a78999a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2174db1d234519985fa7d157f3449a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68076c2a587a4f6b901410b61503a986",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccc892cd342d4090a01854a7163b8d62",
            "value": 798156
          }
        },
        "ea7dd2a888e4429c8cf657c4499f7305": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eed653a7bbe4409ca320a307b9477653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_141649a807dc43c7a8135bf2d248410f",
              "IPY_MODEL_ea2174db1d234519985fa7d157f3449a",
              "IPY_MODEL_b0a798996bf143a39cbc6c779bca2076"
            ],
            "layout": "IPY_MODEL_13c39e293efb4e9f95d769c864f5ba91"
          }
        },
        "fdf3dace2605411a9a1f8a8be48336ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a3a1db2bfc4063bb03356f9accb164",
            "placeholder": "​",
            "style": "IPY_MODEL_16cccf7af037468aace0d555c81c1969",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "fe1ab9eb114e4d1fb7ad7cfb96e3a188": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
